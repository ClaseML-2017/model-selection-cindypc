{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio Cross validation\n",
    "### Valeria Pérez Cong Sánchez 145009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random as rnd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "##Find the best value for the lambda parameter using crossvalidation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Leemos el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/valeriaperezcong/Desktop/ITAM/9/aprendizaje/udemy/DataScience-Python3/regularization_cross_validation/regLinPoli2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Profe: Dividimos en train set y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[[df.columns[-1]]], train_size=0.75)\n",
    "#print X_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Profe: We convert the data sets into panda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profe: Estandarizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This procedure is useful for classroom examples. For a real implementation you have to have a separete method \n",
    "# for transforming the production data so you can transform it as you get it with the fitted scaler\n",
    "## The procedure returns a standardized copy of the input data\n",
    "def normalize(X_train,X_test,Y_train,Y_test,do=True):\n",
    "\n",
    "    scale_X=preprocessing.StandardScaler()\n",
    "    scale_y=preprocessing.StandardScaler()\n",
    "    \n",
    "    train_X=np.copy(X_train)\n",
    "    train_y=np.copy(Y_train)\n",
    "    test_X=np.copy(X_test)\n",
    "    test_y=np.copy(Y_test)\n",
    "    if do:\n",
    "        scale_X.fit(train_X)\n",
    "        scale_y.fit(train_y)\n",
    "        train_X=scale_X.transform(train_X)\n",
    "        train_y=scale_y.transform(train_y)\n",
    "        test_X=scale_X.transform(test_X)\n",
    "        test_y=scale_y.transform(test_y)\n",
    "    return train_X,test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Profe: Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Incremental regularized regression procedures\n",
    "\n",
    "## Transfer function\n",
    "def salida(w,X):\n",
    "    return X.dot(w[1:]) +w[0] #salida= wo + w1*x1\n",
    "\n",
    "## Training function\n",
    "def entrena(X,y,w,la=0.0,eta=0.01):\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        error=y[i]-salida(w,X[i]) #valor real - valor predicho por función salida\n",
    "        w[0]=w[0]+eta*(error) #wo(t)=wo(t-1)+learning_rate*error(t-1)\n",
    "        w[1:]=w[1:]+eta*(error*X[i])-la*w[1:]#wi(t)=wi(t-1)+(learning_rate*error(t-1)*xi)-lambda*wi\n",
    "    return w\n",
    "\n",
    "## Error function\n",
    "def calcError(X,y,w,w0):\n",
    "    return np.mean((X.dot(w)+w0-y)**2) #promedio del error al cuadrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-b94ea7d2a0a7>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-b94ea7d2a0a7>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print calcError(train_X,train_y.flatten(),w[1:],w[0])\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Estandarizamos los datos\n",
    "train_X,test_X,train_y,test_y=normalize(X_train,X_test,Y_train,Y_test)\n",
    "\n",
    "#osea lit estoy haciendo un arreglo de números random para las wi\n",
    "w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])\n",
    "for i in range(100):\n",
    "    w=entrena(train_X,train_y,w,la=0.00)\n",
    "    \n",
    "## flatten here to convert y from a matrix to a vector. Only 1 response variable\n",
    "#print calcError(train_X,train_y.flatten(),w[1:],w[0])\n",
    "#print calcError(test_X,test_y.flatten(),w[1:],w[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Conocimiento nuevo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d6b2e8494c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#X_test=test_set[:,0:test_set.shape[1]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#[reglin2.columns[-1]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_renglones_por_fold=int(round(df.shape[0]/k,0))\n",
    "print(num_renglones_por_fold)\n",
    "#al dividir el número de renglones entre k= tienes el número de rengloes que debe haber en cada fold\n",
    "\n",
    "\n",
    "\n",
    "#el split literal te divide el set en dos según el núm de renglones que tú le des\n",
    "data=np.split(df, [num_renglones_por_fold], axis=0)\n",
    "data[0] #test set- porque es como lo primero que separa usando esos k renglones\n",
    "data[1] #es todo lo demás que queda ya que usaste esos rengloes\n",
    "test_set=data[0] #los datos originales tal cual solo divididos train y test\n",
    "train_set=data[1]\n",
    "#reglin2.columns[0:-1]\n",
    "#X_train=train_set[:,0:train_set.shape[1]]\n",
    "#X_test=test_set[:,0:test_set.shape[1]]\n",
    "#[reglin2.columns[-1]]\n",
    "y_train=train_set[:,train_set.shape[1]]\n",
    "y_test=test_set[:,train_set.shape[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esto lo hacemos solo de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_renglones_por_fold=int(round(df.shape[0]/k,0))\n",
    "print(num_renglones_por_fold)\n",
    "#al dividir el número de renglones entre k= tienes el número de rengloes que debe haber en cada fold\n",
    "\n",
    "\n",
    "\n",
    "#el split literal te divide el set en dos según el núm de renglones que tú le des\n",
    "data=np.split(df, [num_renglones_por_fold], axis=0)\n",
    "data[0] #test set- porque es como lo primero que separa usando esos k renglones\n",
    "data[1] #es todo lo demás que queda ya que usaste esos rengloes\n",
    "test_set=np.array(data[0]) #los datos originales tal cual solo divididos train y test\n",
    "train_set=np.array(data[1])\n",
    "#reglin2.columns[0:-1]\n",
    "X_train=train_set[:,0:train_set.shape[1]]\n",
    "X_test=test_set[:,0:test_set.shape[1]]\n",
    "#[reglin2.columns[-1]]\n",
    "y_train=train_set[:,-1]\n",
    "y_test=test_set[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aportación del profe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Incremental regularized regression procedures\n",
    "\n",
    "## Transfer function\n",
    "def salida(w,X):\n",
    "    return X.dot(w[1:]) +w[0] #salida= wo + w1*x1\n",
    "\n",
    "## Training function\n",
    "def entrena(X,y,w,la=0.0,eta=0.01):\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        error=y[i]-salida(w,X[i]) #valor real - valor predicho por función salida\n",
    "        w[0]=w[0]+eta*(error) #wo(t)=wo(t-1)+learning_rate*error(t-1)\n",
    "        w[1:]=w[1:]+eta*(error*X[i])-la*w[1:]#wi(t)=wi(t-1)+(learning_rate*error(t-1)*xi)-lambda*wi\n",
    "    return w\n",
    "\n",
    "## Error function\n",
    "def calcError(X,y,w,w0):\n",
    "    return np.mean((X.dot(w)+w0-y)**2) #promedio del error al cuadrado\n",
    "\n",
    "\n",
    "#osea lit estoy haciendo un arreglo de números random para las wi\n",
    "w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])\n",
    "#for i in range(100):\n",
    "    #w=entrena(train_X,train_y,w,la=0.00)\n",
    "\n",
    "## flatten here to convert y from a matrix to a vector. Only 1 response variable\n",
    "#print calcError(train_X,train_y.flatten(),w[1:],w[0])\n",
    "#print calcError(test_X,test_y.flatten(),w[1:],w[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-96-e722b43a15e6>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-96-e722b43a15e6>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    X_test=test_set[:,0:test_set.shape[1]]\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_renglones_por_fold=int(round(df.shape[0]/k,0))\n",
    "print(num_renglones_por_fold)\n",
    "#al dividir el número de renglones entre k= tienes el número de rengloes que debe haber en cada fold\n",
    "\n",
    "\n",
    "min_error=3000\n",
    "lam_optima=50\n",
    "errores_train=[]\n",
    "errores_test=[]\n",
    "#donde k es el número de folds que voy a tener\n",
    "for i in range(k):\n",
    "    #aquí estoy separando el set según el número de renglones que debe\n",
    "    #haber en cada fold de acuerdo a mi k\n",
    "    data=np.split(df, [num_renglones_por_fold], axis=0)\n",
    "    test_set=np.array(data[0]) #los datos originales tal cual solo divididos train y test\n",
    "    train_set=np.array(data[1])\n",
    "    X_train=train_set[:,0:train_set.shape[1]\n",
    "    X_test=test_set[:,0:test_set.shape[1]]\n",
    "    Y_train=train_set[:,-1]\n",
    "    Y_test=test_set[:,-1]\n",
    "    #estandarizamos los datos. \n",
    "    train_X,test_X,train_y,test_y=normalize(X_train,X_test,Y_train,Y_test)\n",
    "    #tons hasta este punto ya tenemos los sets separados para cada fold\n",
    "    \n",
    "    #definimos un arreglo random de w\n",
    "    w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])                                       \n",
    "    for w in range(100):\n",
    "        w=entrena(train_X,train_y,w,lam) #entrena te regresa las w optimas\n",
    "    #ya con las w optimas, calculas el error\n",
    "    error_train=calcError(train_X,train_y,w[1:],w[0])\n",
    "    #error_test=calcError(test_X,test_y,w[1:],w[0])\n",
    "    \n",
    "    if error_test < min_error:\n",
    "        min_error=error_test\n",
    "        lam_optima=lam\n",
    "    \n",
    "    data=pd.concat([train_set,test_set]) #ponemos el test set al final del set\n",
    "                      \n",
    "    \n",
    "                      \n",
    "                      \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Cross Validation\n",
    "### Nos regresa el error mínimo y lamda óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#donde k es el número de folds que voy a tener\n",
    "\n",
    "def cross_validation (df,k,eta,lam):\n",
    "    num_renglones_por_fold=int(round(df.shape[0]/k,0))\n",
    "    min_error=300000\n",
    "    lam_optima=50\n",
    "    for i in range(k):\n",
    "        data=np.split(df, [num_renglones_por_fold], axis=0)\n",
    "        test_set=np.array(data[0])\n",
    "        train_set=np.array(data[1])\n",
    "        X_train=train_set[:,0:train_set.shape[1]]\n",
    "        X_test=test_set[:,0:test_set.shape[1]]\n",
    "        Y_train=train_set[:,-1]\n",
    "        Y_test=test_set[:,-1]\n",
    "        train_X,test_X,train_y,test_y=normalize(X_train,X_test,Y_train,Y_test)\n",
    "        w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])\n",
    "        for w in range(100):\n",
    "            w=entrena(train_X,train_y,w,lam,eta)\n",
    "        error_train=calcError(train_X,train_y,w[1:],w[0])\n",
    "        #error_test=calcError(test_X,test_y,w[1:],w[0])\n",
    "        \n",
    "        if error_test < min_error:\n",
    "           min_error=error_test \n",
    "           lam_optima=lam\n",
    "        data=pd.concat([train_set,test_set]) #ponemos el test set al final del set\n",
    "    \n",
    "    return min_error, lam_optima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/valeriaperezcong/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-9f5eba4b9652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mla\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#cross_validation (df,k,eta,lam):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0merrores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#lamda_optima=cross_validation (df,10,0.01,1)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-62c7a2762e69>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(df, k, eta, lam)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentrena\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0merror_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#error_test=calcError(test_X,test_y,w[1:],w[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-21e81056c175>\u001b[0m in \u001b[0;36mentrena\u001b[0;34m(X, y, w, la, eta)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msalida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#valor real - valor predicho por función salida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#wo(t)=wo(t-1)+learning_rate*error(t-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#wi(t)=wi(t-1)+(learning_rate*error(t-1)*xi)-lambda*wi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-21e81056c175>\u001b[0m in \u001b[0;36msalida\u001b[0;34m(w, X)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Transfer function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msalida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#salida= wo + w1*x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## Training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "lam=np.linspace(0,300,500)\n",
    "errores=[]\n",
    "lamdas=[]\n",
    "for la in lam:\n",
    "    #cross_validation (df,k,eta,lam):\n",
    "    error=cross_validation (df,10,0.01,la)[0]\n",
    "    errores.append(error)\n",
    "    #lamda_optima=cross_validation (df,10,0.01,1)[1]\n",
    "    #lamdas.append(lamda_optima)\n",
    "\n",
    "#graficamos\n",
    "plt.plot(lam, errores, 'bo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
